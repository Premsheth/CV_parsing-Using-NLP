{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imac086/anaconda3/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import unicodedata\n",
    "from uszipcode import SearchEngine\n",
    "import MySQLdb\n",
    "import MySQLdb.cursors\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import time\n",
    "\n",
    "class extract_user_details():\n",
    "    \n",
    "    def extract_user_details_doc(self,data,pdf_to_text_list,user):#,ukNames\n",
    "        \n",
    "        cnx = MySQLdb.connect(host = 'localhost',\n",
    "                             database = 'cv_parse',\n",
    "                             user = 'root',\n",
    "                             password = 'root', \n",
    "                             compress = 1,\n",
    "                             cursorclass=MySQLdb.cursors.DictCursor)\n",
    "\n",
    "        cursor = cnx.cursor()\n",
    "        \n",
    "        data = data\n",
    "        pdf_to_text_list = pdf_to_text_list\n",
    "        #print(ukNames[:5])\n",
    "        #infoDict = {}\n",
    "        user = user\n",
    "        user['name'] = []\n",
    "        user['email'] = []\n",
    "        user['phone'] = []\n",
    "        user['zipcode'] = []\n",
    "        user['other_links'] = []\n",
    "        full_name = []\n",
    "        email = []\n",
    "        number = []\n",
    "        zipcode = []\n",
    "        hit = \" \"\n",
    "        \n",
    "        #infoDict['keyword'] = []\n",
    "        #print(ukNames)\n",
    "        clean_txt = [word for word in data.split() if word.lower() not in stopwords.words('english')]\n",
    "        nonum = [char for char in str(clean_txt) if not char.isdigit()]\n",
    "        nopunc = [char for char in nonum if char not in string.punctuation] \n",
    "        data = ''.join(nopunc)\n",
    "        #print(data)\n",
    "\n",
    "        def getName():\n",
    "\n",
    "\n",
    "            #for text in pdf_to_text_list:\n",
    "            \n",
    "            lines = [el.strip() for el in data.split() if len(el) > 0]# Split Documents from \"\\n\" means make new lines\n",
    "            lines = [nltk.word_tokenize(el) for el in lines] # TOkenize each word in each lines\n",
    "            lines = [nltk.pos_tag(el) for el in lines] #\n",
    "            \n",
    "            print\n",
    "            nameHits = []\n",
    "            name = None\n",
    "\n",
    "            grammar = r'NAME: {<NN> <NN.*> <NN.*> <NN.*>*}'\n",
    "            chunkParser = nltk.RegexpParser(grammar)\n",
    "            all_chunked_tokens = []\n",
    "            for tagged_tokens in lines:\n",
    "                # Creates a parse tree\n",
    "                if len(tagged_tokens) == 0: continue # Prevent it from printing warnings\n",
    "                chunked_tokens = chunkParser.parse(tagged_tokens)\n",
    "                \n",
    "                #print(\"Chunked Tokens ===\",chunked_tokens)\n",
    "                all_chunked_tokens.append(chunked_tokens)\n",
    "                for subtree in chunked_tokens.subtrees():\n",
    "                    #  or subtree.label() == 'S' include in if condition if required\n",
    "                    #print(\"===subtree==\",subtree)\n",
    "                    #print(subtree.label())\n",
    "                    if subtree.label() == 'NAME'or subtree.label() == 'S':\n",
    "                        #p = subtree.leaves()\n",
    "                        #print(p)\n",
    "                        for ind, leaf in enumerate(subtree.leaves()):\n",
    "                            #print(ind,\"====\",leaf)\n",
    "                            #print(\"Subtress leaves if it is in given regex for Tag====\",leaf[0].lower(), leaf[1])\n",
    "                            #if leaf[0].lower() in ukNames:\n",
    "                            #    print(\"check half condition====\",leaf[0].lower())\n",
    "                            #leaf[0] = leaf[0].replace(\"'\",\"\")\n",
    "                            le = leaf[0]\n",
    "                            #le = le.replace(\"'\",\"\")\n",
    "                            #print(\"leaf ==== \",leaf[0])\n",
    "                            #start_time = time.time()\n",
    "                            query = \"\"\"SELECT first_name FROM cv_parse.name_table\n",
    "                                    WHERE '\"\"\"+ le + \"\"\"' LIKE CONCAT('%',first_name,'%')\"\"\"\n",
    "                            #print(query)\n",
    "                            cursor.execute(query)\n",
    "                            f_name = cursor.fetchall()\n",
    "                            \n",
    "                            #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "                            #print(f_name)\n",
    "                            \n",
    "                            if f_name and 'NN' in leaf[1]:\n",
    "                            #if leaf[0].lower() in ukNames and 'NN' in leaf[1]:\n",
    "                                #print(\"IN LOOP OF LEAF\")\n",
    "                                #print(\"subtree ====\",subtree.leaves())\n",
    "                                #print(\"leaf value===\", leaf[0])\n",
    "                                hit = f_name[0]['first_name']\n",
    "                                #print(hit)\n",
    "                                #hit = \" \".join([el[0] for el in subtree.leaves()[ind:ind+3]])\n",
    "                                #print(\"After ALL condition Name ========\",hit)\n",
    "                                # Check for the presence of commas, colons, digits - usually markers of non-named entities \n",
    "                                if re.compile(r'[\\d,:]').search(hit): continue\n",
    "                                nameHits.append(hit)\n",
    "                                #print(nameHits)\n",
    "                            \n",
    "                                # Need to iterate through rest of the leaves because of possible mis-matches\n",
    "            # Going for the first name hit\n",
    "            #print(\"IF any name parse=====\",nameHits)\n",
    "            if len(nameHits) > 0:\n",
    "                nameHits = [re.sub(r'[^a-zA-Z \\-]', '', el).strip() for el in nameHits] \n",
    "                name = \" \".join([el[0].upper()+el[1:].lower() for el in nameHits[0].split() if len(el)>0])\n",
    "                otherNameHits = nameHits[1:]\n",
    "                #print(\"Name in IF condition ====\",full_name)\n",
    "                full_name.append(name)\n",
    "                print(full_name)\n",
    "            return full_name\n",
    "\n",
    "        def Email(text):\n",
    "            index = text.find(\"@\")\n",
    "            if index > 0:\n",
    "                #print(text)\n",
    "                em = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "                if em:\n",
    "                    email.append(em.group(0))\n",
    "                    return email\n",
    "\n",
    "        def getPhone(text):\n",
    "            pattern = re.compile(r'([+(]?\\d+[)\\-]?[ \\t\\r\\f\\v]*[(]?\\d{2,}[()\\-]?[ \\t\\r\\f\\v]*\\d{2,}[()\\-]?[ \\t\\r\\f\\v]*\\d*[ \\t\\r\\f\\v]*\\d*[ \\t\\r\\f\\v]*)')\n",
    "            match = pattern.findall(text)\n",
    "            if match:\n",
    "                number.append(match)\n",
    "            return number\n",
    "\n",
    "        def get_zipcode(text):\n",
    "\n",
    "            zip_code = re.search(r'([Gg][Ii][Rr] 0[Aa]{2})|((([A-Za-z][0-9]{1,2})|(([A-Za-z][A-Ha-hJ-Yj-y][0-9]{1,2})|(([A-Za-z][0-9][A-Za-z])|([A-Za-z][A-Ha-hJ-Yj-y][0-9][A-Za-z]?))))\\s?[0-9][A-Za-z]{2})', text)\n",
    "            if zip_code:\n",
    "                zipcode.append(zip_code.group(0))\n",
    "                return zipcode\n",
    "\n",
    "        def get_links(text):\n",
    "            urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "\n",
    "            if len(urls) > 0:\n",
    "                return urls\n",
    "\n",
    "        na = getName()\n",
    "        print(\"Parse Name from DOC ======\",na)\n",
    "        if full_name or na != None:\n",
    "                user['name'] = na\n",
    "\n",
    "        for i,text in enumerate(pdf_to_text_list):\n",
    "            mail = Email(text)\n",
    "            mob = getPhone(text)\n",
    "            zc = get_zipcode(text)\n",
    "            li = get_links(text)\n",
    "\n",
    "            if mail != None:\n",
    "                user['email'] = mail\n",
    "\n",
    "\n",
    "            if mob != None:\n",
    "                user['phone'] = mob\n",
    "\n",
    "\n",
    "            if zc != None:\n",
    "                user['zipcode'] = zc\n",
    "\n",
    "            if li != None:\n",
    "                user['other_links'] = li\n",
    "                \n",
    "        if len(user['email']) > 1:\n",
    "            user['other_links'] = user['email'][1:]\n",
    "        \n",
    "        return user\n",
    "    \n",
    "    def extract_user_detail_pdf(self,data,pdf_to_text_list,text_prop_dict,text_dict):#,ukNames\n",
    "        \n",
    "        \"\"\"\n",
    "        This function extracts user personal data like name, address, phone, email and profile links\n",
    "        from the resume\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        \n",
    "        cnx = MySQLdb.connect(host = 'localhost',\n",
    "                             database = 'cv_parse',\n",
    "                             user = 'root',\n",
    "                             password = 'root', \n",
    "                             compress = 1,\n",
    "                             cursorclass=MySQLdb.cursors.DictCursor)\n",
    "\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        top_text_id = -1\n",
    "        max_val = -100000000\n",
    "\n",
    "        \"\"\"\n",
    "        Extract Name: Iterate all the layout objects to get the text which is present\n",
    "        at the top of the page which is the name of the person\n",
    "        \"\"\"\n",
    "        # FInd closest neighbour\n",
    "        def find_neighbor(key):\n",
    "            \"\"\"\n",
    "            This function will find closest text to the given text in the resume layout\n",
    "            \"\"\"\n",
    "            visited = []\n",
    "\n",
    "            min_vdist, min_hdist = 1000000, 1000000\n",
    "            id = 0\n",
    "            neighbor = \"\"\n",
    "            name_object = text_prop_dict.get(key)\n",
    "\n",
    "            visited.append(name_object)\n",
    "            #print (visited)\n",
    "            for k, lt_obj in text_prop_dict.items():\n",
    "\n",
    "                if (name_object.vdistance(lt_obj) + name_object.hdistance(lt_obj) <= (min_hdist + min_vdist)):\n",
    "\n",
    "                    if (not (name_object.vdistance(lt_obj) == 0 and name_object.hdistance(lt_obj) == 0)):\n",
    "                        #print(name_object.vdistance(lt_obj), name_object.hdistance(lt_obj) )\n",
    "                        text = str(unicodedata.normalize('NFKD', lt_obj.get_text()).encode('utf-8'))\n",
    "                        #print(text)\n",
    "                        if text.__contains__(\"@\"):\n",
    "                            #print(text)\n",
    "                            min_vdist = name_object.vdistance(lt_obj)\n",
    "                            min_hdist = name_object.hdistance(lt_obj)\n",
    "                            #print(min_vdist, min_hdist)\n",
    "                            neighbor = lt_obj\n",
    "                            id = k\n",
    "                            #print(neighbor)\n",
    "            if neighbor == \"\":\n",
    "                return None\n",
    "\n",
    "            visited.append(neighbor)\n",
    "\n",
    "            return neighbor\n",
    "\n",
    "        for key, lt_obj in text_prop_dict.items():\n",
    "            if (lt_obj.bbox[1] > max_val and not lt_obj.get_text().isspace()):\n",
    "                top_text_id = key\n",
    "                max_val = lt_obj.bbox[1]\n",
    "\n",
    "\n",
    "        \"========= for Name, Email, zipcode ============\"\n",
    "\n",
    "        def getName():\n",
    "\n",
    "            #infoDict = {}\n",
    "\n",
    "            #for text in pdf_to_text_list:\n",
    "            lines = [el.strip() for el in data.split() if len(el) > 0]# Split Documents from \"\\n\" means make new lines\n",
    "            lines = [nltk.word_tokenize(el) for el in lines] # TOkenize each word in each lines\n",
    "            lines = [nltk.pos_tag(el) for el in lines] #\n",
    "\n",
    "            otherNameHits = []\n",
    "            nameHits = []\n",
    "            name = None\n",
    "\n",
    "            grammar = r'NAME: {<NN> <NN.*> <NN.*> <NN.*>*}'\n",
    "            chunkParser = nltk.RegexpParser(grammar)\n",
    "            all_chunked_tokens = []\n",
    "            for tagged_tokens in lines:\n",
    "                if len(tagged_tokens) == 0: continue # Prevent it from printing warnings\n",
    "                chunked_tokens = chunkParser.parse(tagged_tokens)\n",
    "                all_chunked_tokens.append(chunked_tokens)\n",
    "                for subtree in chunked_tokens.subtrees():\n",
    "                    #  or subtree.label() == 'S' include in if condition if required\n",
    "                    #print(subtree.label())\n",
    "                    if subtree.label() == 'NAME' or subtree.label() == 'S':\n",
    "                        for ind, leaf in enumerate(subtree.leaves()):\n",
    "                            \n",
    "                            le = leaf[0]\n",
    "                            le = le.replace(\"'\",\"\")\n",
    "\n",
    "                            query = \"\"\"SELECT first_name FROM cv_parse.name_table\n",
    "                                    WHERE '\"\"\"+ le + \"\"\"' LIKE CONCAT('%',first_name,'%')\"\"\"\n",
    "                            \n",
    "                            cnx.set_character_set('utf8')\n",
    "                            cursor.execute(query)\n",
    "                            f_name = cursor.fetchall()\n",
    "\n",
    "                            if f_name and 'NN' in leaf[1]:\n",
    "                            #if leaf[0].lower() in ukNames and 'NN' in leaf[1]:\n",
    "                                hit = f_name[0]['first_name']\n",
    "                                #hit = \" \".join([el[0] for el in subtree.leaves()[ind:ind+3]])\n",
    "                                #print(hit)\n",
    "                                # Check for the presence of commas, colons, digits - usually markers of non-named entities \n",
    "                                if re.compile(r'[\\d,:]').search(hit): continue\n",
    "                                nameHits.append(hit)\n",
    "                                #print(nameHits)\n",
    "                                # Need to iterate through rest of the leaves because of possible mis-matches\n",
    "            # Going for the first name hit\n",
    "            if len(nameHits) > 0:\n",
    "                nameHits = [re.sub(r'[^a-zA-Z \\-]', '', el).strip() for el in nameHits] \n",
    "                name = \" \".join([el[0].upper()+el[1:].lower() for el in nameHits[0].split() if len(el)>0])\n",
    "                otherNameHits = nameHits[1:]\n",
    "\n",
    "\n",
    "            #infoDict['name'] = name\n",
    "            #infoDict['otherNameHits'] = otherNameHits\n",
    "\n",
    "            return name\n",
    "\n",
    "        def Email(txt):\n",
    "            email = None\n",
    "            pattern = re.compile(r'\\S*@\\S*') # Regular expressions which will find email ID from string and extract it\n",
    "            matches = pattern.findall(txt) # Gets all email addresses as a list\n",
    "            return matches\n",
    "\n",
    "        def getPhone(txt):\n",
    "            number = None\n",
    "            try:\n",
    "                #pattern = re.compile(r'([+(]?\\d+[)\\-]?[ \\t\\r\\f\\v]*[(]?\\d{2,}[()\\-]?[ \\t\\r\\f\\v]*\\d{2,}[()\\-]?[ \\t\\r\\f\\v]*\\d*[ \\t\\r\\f\\v]*\\d*[ \\t\\r\\f\\v]*)')\n",
    "                pattern = re.compile(r'\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}')\n",
    "                match = pattern.findall(txt)\n",
    "                # match = [re.sub(r'\\s', '', el) for el in match]\n",
    "                    # Get rid of random whitespaces - helps with getting rid of 6 digits or fewer (e.g. pin codes) strings\n",
    "                # substitute the characters we don't want just for the purpose of checking\n",
    "                match = [re.sub(r'[,.]', '', el) for el in match if len(re.sub(r'[()\\-.,\\s+]', '', el))>6]\n",
    "                    # Taking care of years, eg. 2001-2004 etc.\n",
    "                match = [re.sub(r'\\D$', '', el).strip() for el in match]\n",
    "                    # $ matches end of string. This takes care of random trailing non-digit characters. \\D is non-digit characters\n",
    "                match = [el for el in match if len(re.sub(r'\\D','',el)) <= 15]\n",
    "                    # Remove number strings that are greater than 15 digits\n",
    "                try:\n",
    "                    for el in list(match):\n",
    "                        # Create a copy of the list since you're iterating over it\n",
    "                        if len(el.split('-')) > 3: continue # Year format YYYY-MM-DD\n",
    "                        for x in el.split(\"-\"):\n",
    "                            try:\n",
    "                                # Error catching is necessary because of possibility of stray non-number characters\n",
    "                                # if int(re.sub(r'\\D', '', x.strip())) in range(1900, 2100):\n",
    "                                if x.strip()[-4:].isdigit():\n",
    "                                    if int(x.strip()[-4:]) in range(1900, 2100):\n",
    "                                        # Don't combine the two if statements to avoid a type conversion error\n",
    "                                        match.remove(el)\n",
    "                            except:\n",
    "                                pass\n",
    "                except:\n",
    "                    pass\n",
    "                number = match\n",
    "            except:\n",
    "                pass\n",
    "            return number\n",
    "\n",
    "        \"=========== Functions if not parse from original function\"\n",
    "\n",
    "        #print(top_text_id)\n",
    "        def get_name(top_text_id):\n",
    "            \"\"\"\n",
    "            Extract name from the text\n",
    "            \"\"\"\n",
    "\n",
    "            email_flag = False\n",
    "            phone_flag = False\n",
    "            link_flag = False\n",
    "\n",
    "            name_object = text_prop_dict.get(top_text_id)\n",
    "            text = name_object.get_text()\n",
    "\n",
    "            full_name = []\n",
    "\n",
    "            lines = [el.strip() for el in text.split() if len(el) > 0]# Split Documents from \"\\n\" means make new lines\n",
    "            lines = [nltk.word_tokenize(el) for el in lines] # TOkenize each word in each lines\n",
    "            lines = [nltk.pos_tag(el) for el in lines] #\n",
    "\n",
    "            otherNameHits = []\n",
    "            nameHits = []\n",
    "            name = None\n",
    "\n",
    "            grammar = r'NAME: {<NN.*> <NN.*> <NN.*>*}'\n",
    "            #print(grammar)\n",
    "            # Noun phrase chunk is made out of two or three tags of type NN. (ie NN, NNP etc.) - typical of a name. {2,3} won't work, hence the syntax\n",
    "            # Note the correction to the rule. Change has been made later.\n",
    "            chunkParser = nltk.RegexpParser(grammar)\n",
    "            all_chunked_tokens = []\n",
    "            for tagged_tokens in lines:\n",
    "                # Creates a parse tree\n",
    "                if len(tagged_tokens) == 0: continue # Prevent it from printing warnings\n",
    "                chunked_tokens = chunkParser.parse(tagged_tokens)\n",
    "                all_chunked_tokens.append(chunked_tokens)\n",
    "                for subtree in chunked_tokens.subtrees():\n",
    "                    #  or subtree.label() == 'S' include in if condition if required\n",
    "                    #print(subtree.label())\n",
    "                    if subtree.label() == 'NAME' or subtree.label() == 'S':\n",
    "                        p = subtree.leaves()\n",
    "                        #print(p)\n",
    "                        for ind, leaf in enumerate(subtree.leaves()):\n",
    "                            #print(ind,\"====\",leaf)\n",
    "                            #print(leaf[0].lower(), leaf[1])\n",
    "                            le = leaf[0]\n",
    "                            le = le.replace(\"'\",\"\")\n",
    "                            query = \"\"\"SELECT first_name FROM cv_parse.name_table\n",
    "                                    WHERE '\"\"\"+ le + \"\"\"' LIKE CONCAT('%',first_name,'%')\"\"\"\n",
    "                            \n",
    "                            cnx.set_character_set('utf8')\n",
    "                            cursor.execute(query)\n",
    "                            f_name = cursor.fetchall()\n",
    "\n",
    "                            if f_name and 'NN' in leaf[1]:\n",
    "                            #if leaf[0].lower() in ukNames and 'NN' in leaf[1]:\n",
    "                                hit = f_name[0]['first_name']\n",
    "                                #hit = \" \".join([el[0] for el in subtree.leaves()[ind:ind+3]])\n",
    "                                #print(hit)\n",
    "                                # Check for the presence of commas, colons, digits - usually markers of non-named entities \n",
    "                                if re.compile(r'[\\d,:]').search(hit): continue\n",
    "                                nameHits.append(hit)\n",
    "                                #print(nameHits)\n",
    "                                # Need to iterate through rest of the leaves because of possible mis-matches\n",
    "            # Going for the first name hit\n",
    "            if len(nameHits) > 0:\n",
    "                nameHits = [re.sub(r'[^a-zA-Z \\-]', '', el).strip() for el in nameHits] \n",
    "                name = \" \".join([el[0].upper()+el[1:].lower() for el in nameHits[0].split() if len(el)>0])\n",
    "                otherNameHits = nameHits[1:]\n",
    "\n",
    "            full_name.append(name)\n",
    "            #print(full_name)\n",
    "\n",
    "            # check email in name object\n",
    "            index = text.find(\"@\")\n",
    "            if index > 0:\n",
    "                email_flag = True\n",
    "\n",
    "            # check phone number in name object\n",
    "            cell = re.search(\"\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}\", text)\n",
    "            if cell:\n",
    "                phone_flag = True\n",
    "            #name = \" \".join(full_name)\n",
    "\n",
    "            # check hyperlinks in name object\n",
    "            #print(text)\n",
    "            urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "            if len(urls) > 0:\n",
    "                link_flag = True\n",
    "\n",
    "            return name, email_flag, phone_flag, link_flag\n",
    "\n",
    "        def get_email(text):\n",
    "            \"\"\"\n",
    "            Search email using regex from the given text\n",
    "            :param text: Text which consist of email address\n",
    "            :return: None\n",
    "            \"\"\"\n",
    "            #print(text)\n",
    "\n",
    "            text = str(unicodedata.normalize('NFKD', text).encode('utf-8'))\n",
    "            index = text.find(\"@\")\n",
    "            if index > 0:\n",
    "                email = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "                if email:\n",
    "                    return email.group(0)\n",
    "            else:\n",
    "                for k,v in text_dict.items():\n",
    "                    v = str(unicodedata.normalize('NFKD', v).encode('utf-8'))\n",
    "                    text = re.search(r'[\\w\\.-]+@[\\w\\.-]+', v)\n",
    "                    if text:\n",
    "                        return text.group(0)\n",
    "            return None\n",
    "\n",
    "        def get_cell(text):\n",
    "\n",
    "            text = str(unicodedata.normalize('NFKD', text).encode('utf-8'))\n",
    "            cell = re.search(\"\\d{5}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}\", text)\n",
    "            if cell:\n",
    "                return cell.group(0)\n",
    "            else:\n",
    "                for k,v in text_dict.items():\n",
    "                    v = str(unicodedata.normalize('NFKD', v).encode('utf-8'))\n",
    "                    cell = re.search(\"\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}\", v)\n",
    "\n",
    "                    if cell:\n",
    "                        return cell.group(0)\n",
    "                return None\n",
    "\n",
    "        def get_zipcode(text):\n",
    "\n",
    "            text = str(unicodedata.normalize('NFKD', text).encode('utf-8'))\n",
    "\n",
    "            if text:\n",
    "                zip_code = re.search(r'([Gg][Ii][Rr] 0[Aa]{2})|((([A-Za-z][0-9]{1,2})|(([A-Za-z][A-Ha-hJ-Yj-y][0-9]{1,2})|(([A-Za-z][0-9][A-Za-z])|([A-Za-z][A-Ha-hJ-Yj-y][0-9][A-Za-z]?))))\\s?[0-9][A-Za-z]{2})',text)\n",
    "                if zip_code:\n",
    "                    return(zip_code.group(0))\n",
    "                return None\n",
    "            zip_code = re.search(r'\\b\\d{5}(?:[-\\s]\\d{4})?\\b', text)\n",
    "            #print (zip_code)\n",
    "            if zip_code:\n",
    "                return zip_code.group(0)\n",
    "            else:\n",
    "                for k,v in text_dict.items():\n",
    "                    v = str(unicodedata.normalize('NFKD', v).encode('utf-8'))\n",
    "                    zip_code = re.search(r'\\b\\d{5}(?:[-\\s]\\d{4})?\\b', v)\n",
    "                    if zip_code:\n",
    "                        return zip_code.group(0)\n",
    "            return None\n",
    "\n",
    "        def get_links(text):\n",
    "\n",
    "            text = str(unicodedata.normalize('NFKD', text).encode('utf-8'))\n",
    "            urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "\n",
    "            if len(urls) > 0:\n",
    "                return urls\n",
    "            else:\n",
    "                result = []\n",
    "                for k, v in text_dict.items():\n",
    "                    v = str(unicodedata.normalize('NFKD', v).encode('utf-8'))\n",
    "                    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',v)\n",
    "                    if len(urls) > 0:\n",
    "                        result.extend(urls)\n",
    "            return result\n",
    "\n",
    "        user = {}\n",
    "        user['name'] = []\n",
    "        user['email'] = []\n",
    "        user['phone'] = []\n",
    "        user['zipcode'] = []\n",
    "        #user['other_links'] = []\n",
    "\n",
    "        neighbor = find_neighbor(top_text_id)\n",
    "        #print(neighbor)\n",
    "\n",
    "        full_name, email_flag, phone_flag, link_flag = get_name(top_text_id)\n",
    "        if full_name:\n",
    "            user['name'].append(full_name)\n",
    "        else:\n",
    "            user['name'].append(None)\n",
    "\n",
    "        if not email_flag and not neighbor == None:\n",
    "            user['email'].append((get_email(neighbor.get_text())))\n",
    "        else:\n",
    "            name_object = text_prop_dict.get(top_text_id)\n",
    "            text = name_object.get_text()\n",
    "            user['email'].append(get_email(text))\n",
    "            if not user['email']:\n",
    "                user['email'].append(Email(data))\n",
    "\n",
    "        if not phone_flag and not neighbor == None:\n",
    "            user['phone'].append(get_cell(neighbor.get_text()))\n",
    "        else:\n",
    "            name_object = text_prop_dict.get(top_text_id)\n",
    "            text = name_object.get_text()\n",
    "            user['phone'].append((get_cell(text)))\n",
    "            if not user['phone']:\n",
    "                user['phone'].append((getPhone(data)))\n",
    "\n",
    "        if not neighbor == None:\n",
    "\n",
    "            zipcode = get_zipcode(neighbor.get_text())\n",
    "\n",
    "            # Use zipcode dictionary to find state and city\n",
    "            #search = SearchEngine()\n",
    "            #zip_obj = search.by_zipcode(zipcode)\n",
    "            #state = zip_obj.state\n",
    "            #city = zip_obj.major_city\n",
    "            user['zipcode'].append(zipcode)\n",
    "        else:\n",
    "            zipcode = get_zipcode(data)\n",
    "            user['zipcode'].append(zipcode) \n",
    "\n",
    "        if not link_flag and not neighbor == None:\n",
    "            user['other_links'] = (get_links(neighbor.get_text()))\n",
    "        else:\n",
    "            name_object = text_prop_dict.get(top_text_id)\n",
    "            text = name_object.get_text()\n",
    "            user['other_links'] = (get_links(text))\n",
    "\n",
    "        return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ud = extract_user_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_user_details_doc() missing 4 required positional arguments: 'data', 'pdf_to_text_list', 'ukNames', and 'user'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d245c6aa03ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_user_details_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: extract_user_details_doc() missing 4 required positional arguments: 'data', 'pdf_to_text_list', 'ukNames', and 'user'"
     ]
    }
   ],
   "source": [
    "ud.extract_user_details_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than one character\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s= 'ihj'\n",
    "if re.search(r'^[a-zA-Z]{1}$',s) is None:\n",
    "    print(\"More than one character\")\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
